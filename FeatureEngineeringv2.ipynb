{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "yrBVg004ieo1",
    "outputId": "f5f9b0f0-e9c4-4f5c-8910-c5d8e803073f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting holidays\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/da/7d0642a8b94ea413fc7005f4538c01475a45b420d705f57481752552ac55/holidays-0.9.8.tar.gz (64kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 505kB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.6/site-packages (from holidays)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from holidays)\n",
      "Building wheels for collected packages: holidays\n",
      "  Running setup.py bdist_wheel for holidays ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/6f/d2/1a/5854fb5211d237db046d9ae62674a112d020d84c40a729dd02\n",
      "Successfully built holidays\n",
      "Installing collected packages: holidays\n",
      "Successfully installed holidays-0.9.8\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "!pip install holidays\n",
    "import holidays\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distributions(salesMonth):\n",
    "    salesMonth.aggVODKA = salesMonth.aggVODKA / salesMonth.numRecords\n",
    "    salesMonth.aggRUM = salesMonth.aggRUM / salesMonth.numRecords\n",
    "    salesMonth.aggBRANDIES = salesMonth.aggBRANDIES / salesMonth.numRecords\n",
    "    salesMonth.aggTEQUILA = salesMonth.aggTEQUILA / salesMonth.numRecords\n",
    "    salesMonth.aggSCHNAPPS = salesMonth.aggSCHNAPPS / salesMonth.numRecords\n",
    "    salesMonth.aggWHISKIES = salesMonth.aggWHISKIES / salesMonth.numRecords\n",
    "    salesMonth.aggSCOTCH = salesMonth.aggSCOTCH / salesMonth.numRecords\n",
    "    salesMonth.aggOTHER = salesMonth.aggOTHER / salesMonth.numRecords\n",
    "    salesMonth.aggLIQUEURS = salesMonth.aggLIQUEURS / salesMonth.numRecords\n",
    "    return salesMonth\n",
    "def clean_cities(sales):\n",
    "    spellingMapping = {\n",
    "    \"clearlake\": \"clear lake\",\n",
    "    \"dewitt\": \"de witt\",\n",
    "    \"guttenburg\" : \"guttenberg\",\n",
    "    \"grand mounds\": \"grand mound\",\n",
    "    \"jewell\": \"jewell junction\",\n",
    "    \"kellog\": \"kellogg\",\n",
    "    \"ottuwma\": \"ottumwa\",\n",
    "    \"otumwa\": \"ottumwa\",\n",
    "    \"lemars\": \"le mars\",\n",
    "    \"leclaire\": \"le claire\"\n",
    "    }   \n",
    "    sales['City'] = sales['City'].map(lambda x: x.lower().replace(\"'\", \"\").strip())\n",
    "    sales['City'] = sales['City'].map(lambda x: spellingMapping.get(x, x))\n",
    "    sales['City'] = sales['City'].map(lambda x: x.replace('mt', 'mount'))\n",
    "    sales['City'] = sales['City'].map(lambda x: x.replace('saint', 'st.'))\n",
    "    sales['City'] = sales['City'].map(lambda x: re.sub('^ft.', 'fort', x))\n",
    "    sales['City'] = sales['City'].map(lambda x: re.sub('^st ', 'st. ', x))\n",
    "    return sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "nVnWUH5llnaJ",
    "outputId": "e70f63ef-d8a2-4a33-bbe1-b220f3c4fcfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colorado springs\n"
     ]
    }
   ],
   "source": [
    "#Aggregate by City and Day\n",
    "sales = pd.read_csv('GrossSalesCountsDay.csv')\n",
    "sales.Date = pd.to_datetime(sales.Date, infer_datetime_format=True)\n",
    "sales = clean_cities(sales)\n",
    "sales = get_distributions(sales)\n",
    "\n",
    "census = pd.read_csv(\"CensusData.csv\")\n",
    "census['City'] = census['City'].map(lambda x: x.lower().replace(\"'\", \"\").strip())\n",
    "censusunique = np.unique(census['City'])\n",
    "for city in np.unique(sales['City']):\n",
    "    if city not in censusunique:\n",
    "        print(city)\n",
    "        \n",
    "merged = sales.merge(census, on='City', how='inner')\n",
    "merged = merged.drop(\"Unnamed: 0\", axis = 1)\n",
    "merged['Volume Per Capita'] = merged['Volume Sold (Liters)'] / merged['Population']\n",
    "merged['Bottles Per Capita'] = merged['Bottles Sold'] / merged['Population']\n",
    "merged['Sales Per Capita'] = merged['Sale (Dollars)'] / merged['Population']\n",
    "\n",
    "one_hot_city = pd.get_dummies(merged.City)\n",
    "merged = pd.merge(merged, one_hot_city, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "merged.Date = pd.to_datetime(merged.Date, infer_datetime_format=True)\n",
    "# The day of the week with Monday=0, Sunday=6\n",
    "merged['Dayofweek'] = merged.Date.dt.dayofweek\n",
    "# The week ordinal of the year\n",
    "merged['Week'] = merged.Date.dt.weekofyear\n",
    "merged['Month'] = merged.Date.dt.month\n",
    "\n",
    "#print(\"merged.Date = {} and type = {}\".format(merged.Date, type(merged.Date)))\n",
    "us_holidays = holidays.UnitedStates()\n",
    "merged['Holiday'] = merged.apply(lambda x: x['Date'] in us_holidays, axis =1)\n",
    "merged.to_csv(\"GrossSalesDay1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colorado springs\n"
     ]
    }
   ],
   "source": [
    "#aggregate by City, Year, and Month\n",
    "sales = pd.read_csv('GrossSalesCountsDay.csv')\n",
    "sales.Date = pd.to_datetime(sales.Date, infer_datetime_format=True)\n",
    "sales = clean_cities(sales)\n",
    "\n",
    "sales['Month'] = sales.Date.dt.month\n",
    "sales['Year'] = sales.Date.dt.year\n",
    "us_holidays = holidays.UnitedStates()\n",
    "sales['Holiday Sales'] = sales.apply(lambda x: x['Date'] in us_holidays, axis =1).astype(int)\n",
    "\n",
    "salesMonth = sales.groupby(['City', 'Year', 'Month']).sum().reset_index()\n",
    "sales = get_distributions(salesMonth)\n",
    "\n",
    "census = pd.read_csv(\"CensusData.csv\")\n",
    "census['City'] = census['City'].map(lambda x: x.lower().replace(\"'\", \"\").strip())\n",
    "censusunique = np.unique(census['City'])\n",
    "for city in np.unique(sales['City']):\n",
    "    if city not in censusunique:\n",
    "        print(city)\n",
    "merged = sales.merge(census, on='City', how='inner')\n",
    "merged = merged.drop(\"Unnamed: 0\", axis = 1)\n",
    "merged['Volume Per Capita'] = merged['Volume Sold (Liters)'] / merged['Population']\n",
    "merged['Bottles Per Capita'] = merged['Bottles Sold'] / merged['Population']\n",
    "merged['Sales Per Capita'] = merged['Sale (Dollars)'] / merged['Population']\n",
    "\n",
    "one_hot_city = pd.get_dummies(merged.City)\n",
    "merged = pd.merge(merged, one_hot_city, left_index=True, right_index=True)\n",
    "\n",
    "merged.to_csv(\"GrossSalesCityYearMonth.csv\" , index=False)\n",
    "month_data = merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colorado springs\n"
     ]
    }
   ],
   "source": [
    "#Aggregate by City, Year, and Week\n",
    "sales = pd.read_csv('GrossSalesCountsDay.csv')\n",
    "sales.Date = pd.to_datetime(sales.Date, infer_datetime_format=True)\n",
    "sales = clean_cities(sales)\n",
    "\n",
    "sales['Week'] = sales.Date.dt.weekofyear\n",
    "sales['Year'] = sales.Date.dt.year\n",
    "\n",
    "us_holidays = holidays.UnitedStates()\n",
    "sales['Holiday Sales'] = sales.apply(lambda x: x['Date'] in us_holidays, axis =1).astype(int)\n",
    "salesMonth = sales.groupby(['City', 'Year', 'Week']).sum().reset_index()\n",
    "sales = get_distributions(salesMonth)\n",
    "census = pd.read_csv(\"CensusData.csv\")\n",
    "census['City'] = census['City'].map(lambda x: x.lower().replace(\"'\", \"\").strip())\n",
    "censusunique = np.unique(census['City'])\n",
    "for city in np.unique(sales['City']):\n",
    "    if city not in censusunique:\n",
    "        print(city)\n",
    "merged = sales.merge(census, on='City', how='inner')\n",
    "merged = merged.drop(\"Unnamed: 0\", axis = 1)\n",
    "merged['Volume Per Capita'] = merged['Volume Sold (Liters)'] / merged['Population']\n",
    "merged['Bottles Per Capita'] = merged['Bottles Sold'] / merged['Population']\n",
    "merged['Sales Per Capita'] = merged['Sale (Dollars)'] / merged['Population']\n",
    "one_hot_city = pd.get_dummies(merged.City)\n",
    "merged = pd.merge(merged, one_hot_city, left_index=True, right_index=True)\n",
    "\n",
    "merged.to_csv(\"GrossSalesCityYearWeek.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FeatureEngineering.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
